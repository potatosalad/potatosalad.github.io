<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Latency of Native Functions for Erlang and Elixir &middot; potatosalad
    
  </title>

  <!-- CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/nvd3/1.8.5/nv.d3.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/public/css/main.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Latency of Native Functions for Erlang and Elixir | potatosalad</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Latency of Native Functions for Erlang and Elixir" />
<meta name="author" content="Andrew Bennett" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Erlang and C first appeared within 14 years* of one another." />
<meta property="og:description" content="Erlang and C first appeared within 14 years* of one another." />
<link rel="canonical" href="https://potatosalad.io/2017/08/05/latency-of-native-functions-for-erlang-and-elixir" />
<meta property="og:url" content="https://potatosalad.io/2017/08/05/latency-of-native-functions-for-erlang-and-elixir" />
<meta property="og:site_name" content="potatosalad" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-08-05T00:00:00-05:00" />
<script type="application/ld+json">
{"dateModified":"2017-08-05T00:00:00-05:00","datePublished":"2017-08-05T00:00:00-05:00","headline":"Latency of Native Functions for Erlang and Elixir","mainEntityOfPage":{"@type":"WebPage","@id":"https://potatosalad.io/2017/08/05/latency-of-native-functions-for-erlang-and-elixir"},"author":{"@type":"Person","name":"Andrew Bennett"},"url":"https://potatosalad.io/2017/08/05/latency-of-native-functions-for-erlang-and-elixir","description":"Erlang and C first appeared within 14 years* of one another.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js" charset="utf-8"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/nvd3/1.8.5/nv.d3.min.js"></script>
</head>


  <body>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73459380-1', 'auto');
  ga('send', 'pageview');

</script>


    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
<!--   <div class="sidebar-item">
    <p>The Development Blog of Andrew Bennett
</p>
  </div> -->

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
    <a class="sidebar-nav-item" href="https://github.com/potatosalad"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">potatosalad</span></a>

    

    
    <a class="sidebar-nav-item" href="https://twitter.com/potatosaladx"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">potatosaladx</span></a>

    
  </nav>

  <div class="sidebar-nav-item">
    <span>Tags</span>
  </div>

  <nav class="sidebar-nav">
    
    
      <a class="sidebar-nav-item" href=/tag/c/>C</a>
    
      <a class="sidebar-nav-item" href=/tag/elixir/>Elixir</a>
    
      <a class="sidebar-nav-item" href=/tag/erlang/>Erlang</a>
    
      <a class="sidebar-nav-item" href=/tag/performance/>Performance</a>
    
      <a class="sidebar-nav-item" href=/tag/http%2F2/>HTTP/2</a>
    
      <a class="sidebar-nav-item" href=/tag/gen_statem/>gen_statem</a>
    
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2020. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">potatosalad</a>
            <small>blog</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post post-2017-08-05-b55da7d7">
  <h1 class="post-title">Latency of Native Functions for Erlang and Elixir</h1>
  <span class="post-date">5 Aug, 2017</span>
  <span class="post-comments"><a href="#disqus_thread"></a></span>
  <hr>
  <p>Erlang and C first appeared within 14 years<sup><a href="#footnote-post-2017-08-05-b55da7d7-1">*</a></sup> of one another.</p>

<p>In the 30+ years together both languages have gone through many changes.  The methods of interoperability have also changed with time.</p>

<p>There are now <em>several</em> methods to integrate native functions with Erlang or Elixir code.</p>

<p>My goal in writing this article is to explore these methods and measure latency from the perspective of the Erlang VM.</p>

<p><small><sup><a name="footnote-post-2017-08-05-b55da7d7-1">*</a></sup> Based on C first appearing in 1972 and Erlang first appearing in 1986.</small></p>

<p><acronym title="Too long; didn't read"><strong>TL;DR</strong></acronym> Need a native function (C, C++, Rust, etc.) integrated with Erlang or Elixir that is isolation, complexity, or latency sensitive?</p>

<p>Having a hard time deciding whether you should write a node, port, port driver, or NIF?</p>

<p>Use this potentially helpful and fairly unscientific table to help you decide:</p>

<table>
  <tr>
    <th>Type</th>
    <th>Isolation</th>
    <th>Complexity</th>
    <th>Latency</th>
  </tr>
  <tr>
    <td><tt>Node</tt></td>
    <td style="background-color: #cfc;"><tt>Network</tt></td>
    <td style="background-color: #fcc;"><tt>Highest</tt></td>
    <td style="background-color: #fcc;"><tt>Highest</tt></td>
  </tr>
  <tr>
    <td><tt>Port</tt></td>
    <td style="background-color: #ffc;"><tt>Process</tt></td>
    <td style="background-color: #fcc;"><tt>High</tt></td>
    <td style="background-color: #fcc;"><tt>High</tt></td>
  </tr>
  <tr>
    <td><tt>Port Driver</tt></td>
    <td style="background-color: #fcc;"><tt>Shared</tt></td>
    <td style="background-color: #ffc;"><tt>Low</tt></td>
    <td style="background-color: #ffc;"><tt>Low</tt></td>
  </tr>
  <tr>
    <td><tt>NIF</tt></td>
    <td style="background-color: #fcc;"><tt>Shared</tt></td>
    <td style="background-color: #cfc;"><tt>Lowest</tt></td>
    <td style="background-color: #cfc;"><tt>Lowest</tt></td>
  </tr>
</table>

<h3 id="overview">Overview</h3>

<p>Erlang has an excellent <a href="http://erlang.org/doc/tutorial/users_guide.html">Interoperability Tutorial User’s Guide</a> that provides examples for the different ways of integrating a program written in Erlang or Elixir with a program written in another programming language.</p>

<p>The simplest test I could think of to measure the latency was to round trip an Erlang term from the Erlang VM to the native function and back again.</p>

<p>However, the term would need to be large enough to hopefully expose any weaknesses for a given implementation.</p>

<p>Following the guidance from Erlang’s documentation, I implemented slightly more complex examples of the following methods of interoperability:</p>

<ol>
  <li><a href="http://erlang.org/doc/tutorial/cnode.html">C Node</a>
    <ul>
      <li><a href="https://github.com/potatosalad/elixirconf2017/tree/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/c_node">C source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/lib/latency/c_node.ex">Elixir source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/src/latency_c_node.erl">Erlang source</a></li>
    </ul>
  </li>
  <li><a href="http://erlang.org/doc/tutorial/nif.html">NIF</a>
    <ul>
      <li><a href="https://github.com/potatosalad/elixirconf2017/tree/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif">C source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/lib/latency/nif.ex">Elixir source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/src/latency_nif.erl">Erlang source</a></li>
    </ul>
  </li>
  <li><a href="http://erlang.org/doc/tutorial/c_portdriver.html">Port Driver</a>
    <ul>
      <li><a href="https://github.com/potatosalad/elixirconf2017/tree/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/drv">C source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/lib/latency/port_driver.ex">Elixir source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/src/latency_drv.erl">Erlang source</a></li>
    </ul>
  </li>
  <li><a href="http://erlang.org/doc/tutorial/c_port.html">Port</a>
    <ul>
      <li><a href="https://github.com/potatosalad/elixirconf2017/tree/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/port">C source</a></li>
      <li><a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/lib/latency/port.ex">Elixir source</a></li>
    </ul>
  </li>
</ol>

<p>The NIF and Port Driver implementations have a few different internal strategies for additional comparison (like Dirty NIF and <code class="highlighter-rouge">iodata()</code> based port output).</p>

<p>Certain methods should have higher levels of latency based on serialization and isolation requirements.  For example, a C Node requires serialization of the entire term in order to pass it back and forth over a TCP connection.  A NIF, by comparison, requires no serialization and operates on the term itself in memory.</p>

<p>Each implementation was tested with a ~64KB binary full of 1’s as the sole element of a 1-arity tuple for 100,000 iterations.  The measured elapsed time for each method were then fed into <a href="http://hdrhistogram.org/">HDR Histogram</a> for latency analysis.</p>

<p>In other words, I essentially did the following on the <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/lib/latency.ex"><code class="highlighter-rouge">Latency</code></a> module:</p>

<div class="language-elixir highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">term</span> <span class="o">=</span> <span class="p">{</span><span class="ss">:binary</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="o">&lt;&lt;</span><span class="mi">1</span><span class="o">&gt;&gt;</span><span class="p">,</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">64</span><span class="p">)}</span>
<span class="no">Latency</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="mi">100_000</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="c-nodeport-versus-port-drivernif">C Node/Port versus Port Driver/NIF</h3>

<p>First, let’s compare the 4 major types of native functions:</p>

<p><a href="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart1.png"><img src="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart1.png" alt="chart1" /></a></p>

<p>Comparison of results using the order of magnitude of average latency:</p>

<table>
  <tr>
    <th>Type</th>
    <th>Isolation</th>
    <th>Latency</th>
  </tr>
  <tr>
    <td><tt>Node</tt></td>
    <td style="background-color: #cfc;"><tt>Network</tt></td>
    <td style="background-color: #fcc; text-align: right;"><tt>~100μs</tt></td>
  </tr>
  <tr>
    <td><tt>Port</tt></td>
    <td style="background-color: #ffc;"><tt>Process</tt></td>
    <td style="background-color: #fcc; text-align: right;"><tt>~100μs</tt></td>
  </tr>
  <tr>
    <td><tt>Port Driver</tt></td>
    <td style="background-color: #fcc;"><tt>Shared</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~10μs</tt></td>
  </tr>
  <tr>
    <td><tt>NIF</tt></td>
    <td style="background-color: #fcc;"><tt>Shared</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~0.1μs</tt></td>
  </tr>
</table>

<p>These tests were run on the same machine, so there’s little surpise that the Node and Port latencies are essentially just benchmarking pipe speeds of the operating system itself (in this case macOS 10.12).  Were the Erlang and C nodes located on different machines, I would expect the latency to be higher for the Node test.</p>

<p>It’s also worth noting that C Nodes and Ports are the most isolated form of native function calling from the Erlang VM.  This means that a bug in the C code that causes the C Node or Port to crash will not take down the entire VM.</p>

<h3 id="port-driver">Port Driver</h3>

<p>Port drivers, under certain circumstances, can be roughly as fast as a NIF.  This is especially true for very small terms or when the majority of the work performed is I/O or binary-based.</p>

<p>The documentation for <a href="http://erlang.org/doc/man/driver_entry.html"><code class="highlighter-rouge">driver_entry</code></a> mentions that <a href="http://erlang.org/doc/man/erlang.html#port_control-3"><code class="highlighter-rouge">erlang:port_control/3</code></a> should be the fastest way to call a native function.  This seems to be true for very small terms, but larger terms cause the performance to be almost identical to <a href="http://erlang.org/doc/man/erlang.html#port_call-3"><code class="highlighter-rouge">erlang:port_call/3</code></a>.  Converting terms to the <a href="http://erlang.org/doc/apps/erts/erl_ext_dist.html">External Term Format</a> and sending with <a href="http://erlang.org/doc/man/erlang.html#port_command-3"><code class="highlighter-rouge">erlang:port_command/3</code></a> (which in turn calls the <a href="http://erlang.org/doc/man/driver_entry.html#outputv"><code class="highlighter-rouge">outputv</code></a> callback) actually appears to have slightly less latency.</p>

<ol>
  <li><a href="http://erlang.org/doc/man/driver_entry.html#call"><code class="highlighter-rouge">call</code></a> — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/drv/latency_drv.c#L61-L70">lines 61-70 of <code class="highlighter-rouge">latency_drv.c</code></a></li>
  <li><a href="http://erlang.org/doc/man/driver_entry.html#control"><code class="highlighter-rouge">control</code></a> — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/drv/latency_drv.c#L41-L52">lines 41-52 of <code class="highlighter-rouge">latency_drv.c</code></a></li>
  <li><a href="http://erlang.org/doc/man/driver_entry.html#outputv"><code class="highlighter-rouge">outputv</code></a> — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/drv/latency_drv.c#L54-L59">lines 54-59 of <code class="highlighter-rouge">latency_drv.c</code></a></li>
</ol>

<p><a href="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart2.png"><img src="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart2.png" alt="chart2" /></a></p>

<p>Also worth noting is the type of data allowed to be sent to the Port Driver.  For example, <a href="http://erlang.org/doc/man/erlang.html#port_call-3"><code class="highlighter-rouge">erlang:port_call/3</code></a> allows terms to be sent, but internally converts them to the external term format.  The other types are similar to C Node and Port implementations and require any terms sent to first be converted.</p>

<table>
  <tr>
    <th>Type</th>
    <th>Data Type</th>
    <th>Latency</th>
  </tr>
  <tr>
    <td><tt>call</tt></td>
    <td style="background-color: #cfc;"><tt>term()</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~15μs</tt></td>
  </tr>
  <tr>
    <td><tt>control</tt></td>
    <td style="background-color: #ffc;"><tt>iodata()</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~15μs</tt></td>
  </tr>
  <tr>
    <td><tt>outputv</tt></td>
    <td style="background-color: #ffc;"><tt>iodata()</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~10μs</tt></td>
  </tr>
</table>

<h3 id="nif">NIF</h3>

<p><a href="http://erlang.org/doc/man/erl_nif.html">Native Implemented Function (NIF)</a> is a relatively recent addition to OTP and is the fastest way to call native functions.  However, a mis-behaving NIF can easily destabilize or crash the entire Erlang VM.</p>

<p><a href="http://erlang.org/doc/man/erl_nif.html#dirty_nifs">Dirty NIF</a> and Yielding (or Future) NIF with <a href="http://erlang.org/doc/man/erl_nif.html#enif_schedule_nif"><code class="highlighter-rouge">enif_schedule_nif</code></a> are even more recent additions that help prevent blocking the Erlang VM schedulers during execution or (in the case of I/O) waiting.</p>

<ol>
  <li>Dirty CPU — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L20-L24">lines 20-24 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
  <li>Dirty I/O — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L26-L30">lines 26-30 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
  <li>Future — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L32-L36">lines 32-36 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
  <li>Normal — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L14-L18">lines 14-18 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
</ol>

<p><a href="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart3.png"><img src="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart3.png" alt="chart3" /></a></p>

<p>The Normal NIF call is the only one that doesn’t have any sort of context switching involved.  The Yielding (or Future) NIF also doesn’t involve much of a context switch as it yields control back to the same scheduler that dispatched the call.  Dirty NIF calls, however, result in a ~2μs context switch delay as the function gets enqueued on the dirty thread pool.</p>

<table>
  <tr>
    <th>Type</th>
    <th>Context Switch</th>
    <th>Latency</th>
  </tr>
  <tr>
    <td><tt>Dirty CPU</tt></td>
    <td style="background-color: #ffc;"><tt>Thread Queue</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~2.0μs</tt></td>
  </tr>
  <tr>
    <td><tt>Dirty I/O</tt></td>
    <td style="background-color: #ffc;"><tt>Thread Queue</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~2.0μs</tt></td>
  </tr>
  <tr>
    <td><tt>Future</tt></td>
    <td style="background-color: #ffc;"><tt>Yield</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~0.5μs</tt></td>
  </tr>
  <tr>
    <td><tt>Normal</tt></td>
    <td style="background-color: #cfc;"><tt>None</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~0.1μs</tt></td>
  </tr>
</table>

<p>Just for fun, I was curious about the latency differences between the new Dirty NIF functionality and the previous method of using a Threaded NIF or the Async NIF (or Thread Queue) by <a href="https://github.com/gburd">Gregory Burd</a>.</p>

<ol>
  <li>Thread New — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L38-L72">lines 38-72 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
  <li>Thread Queue — <a href="https://github.com/potatosalad/elixirconf2017/blob/555763cd7505bf1ffcaa7c7099161a9e74c63a3f/apps/latency/c_src/nif/latency_nif.c#L74-L90">lines 74-90 of <code class="highlighter-rouge">latency_nif.c</code></a></li>
</ol>

<p><a href="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart4.png"><img src="https://potatosalad.io/assets/post-2017-08-05-b55da7d7/chart4.png" alt="chart4" /></a></p>

<p>As it turns out, creating and destroying a thread for each and every call is unwise for a few reasons; poor latency being one of them.  The Async NIF (or Thread Queue) has the advantage of providing a pool per NIF instead of having to share the global thread pool with other NIFs.  However, Dirty NIF thread pools are definitely more optimized and are typically 4x faster than the Async NIF implementation.</p>

<table>
  <tr>
    <th>Type</th>
    <th>Pool Type</th>
    <th>Latency</th>
  </tr>
  <tr>
    <td><tt>Thread New</tt></td>
    <td style="background-color: #fcc;"><tt>None</tt></td>
    <td style="background-color: #fcc; text-align: right;"><tt>~50.0μs</tt></td>
  </tr>
  <tr>
    <td><tt>Thread Queue</tt></td>
    <td style="background-color: #ffc;"><tt>NIF</tt></td>
    <td style="background-color: #ffc; text-align: right;"><tt>~8.0μs</tt></td>
  </tr>
  <tr>
    <td><tt>Dirty CPU</tt></td>
    <td style="background-color: #ffc;"><tt>Global</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~2.0μs</tt></td>
  </tr>
  <tr>
    <td><tt>Dirty I/O</tt></td>
    <td style="background-color: #ffc;"><tt>Global</tt></td>
    <td style="background-color: #cfc; text-align: right;"><tt>~2.0μs</tt></td>
  </tr>
</table>

<h3 id="conclusions">Conclusions</h3>

<p>If isolation from/protection of the Erlang VM is highest priority, a C Node or Port are your best options.  If your primary concern is low latency or low complexity, using a NIF for your native function is your best option.</p>

<p><em>As a side note:</em> For very specific I/O operations, a Port Driver still may be the best option.  OTP-20 has the new <a href="http://erlang.org/doc/man/erl_nif.html#enif_select"><code class="highlighter-rouge">enif_select</code></a>, which is starting to transition some of those I/O benefits to the NIF world, so this may not be true statement in the near future.</p>

</div>

<span class="post-tags">Tags: <a href="/tag/c/" rel="tag">C</a>, <a href="/tag/elixir/" rel="tag">Elixir</a>, <a href="/tag/erlang/" rel="tag">Erlang</a>, <a href="/tag/performance/" rel="tag">Performance</a></span>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2017/10/13/time-out-elixir-state-machines-versus-servers">
            Time-Out: Elixir State Machines versus Servers
            <small>13 Oct 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2017/08/20/load-testing-cowboy-2-0-0-rc-1">
            Load Testing cowboy 2.0.0-rc.1
            <small>20 Aug 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2016/02/06/erlang-nif-with-timeslice-reductions">
            Erlang NIF with timeslice reductions
            <small>06 Feb 2016</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

  <div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
var disqus_config = function () {
    this.page.url = 'https://potatosalad.io/2017/08/05/latency-of-native-functions-for-erlang-and-elixir';
    this.page.identifier = 'post-2017-08-05-b55da7d7';
};
(function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');

    s.src = 'https://potatosalad.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
    <script id="dsq-count-scr" src="//potatosalad.disqus.com/count.js" async></script>
  </body>
</html>
